---
title: "Assignment 2"
author: "Group A -"
date: ""
output:
  pdf_document: default
  word_document: default
  html_document:
    df_print: paged
  html_notebook: default
header-includes:
- \usepackage{bbm}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1 Findings

+ What are the major determinants of high crime rates?
+ Are there areas of the US with unusually low or high crime rates that do not conform to the general pattern?
+ Are the causes of violent and non-violent crime similar, or are there important differences?

Our models found several major determinants of high crime rates. Income, region, the proportion of population born in foreign countries, house occupancy, urbanisation, education, house/rental prices and the environment in which children are raised are all important factors in models for both violent and non-violent crime. There are some differences in how these factors influence violent and non-violent crime:

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Variable} & \textbf{Violent} & \textbf{Non-Violent} \\ \hline
Intercept & 6.28 & 10.8 \\ \hline
\texttt{region} - North East & -0.171 & -0.161 \\ \hline
\texttt{region} - West & 0.206 & 0.113 \\ \hline
\texttt{region} - South & 0.182 & 0.0388 \\ \hline
\texttt{isUrban} - Urban & 0.151 & 0.0787 \\ \hline
\texttt{medIncome} & -0.112 & 0 \\ \hline
\texttt{pctWdiv} & -0.0113 & -0.00298 \\ \hline
\texttt{rentMed} & 0.0688 & 0 \\ \hline
\texttt{rentQrange} & 0 & 0.107 \\ \hline
\texttt{ownHousMed} & 0 & -0.0650 \\ \hline
\texttt{pctKids2Par} & -0.0182 & -0.0171 \\ \hline
\texttt{pctKidsBornNevrMarr} & 0.702 & 0 \\ \hline
\texttt{pctHousOccup} & -0.0000279 & -0.0000198 \\ \hline
\texttt{pctVacantBoarded} & 0.131 & 0.0666 \\ \hline
\texttt{pctVacant6up} & -0.00318 & -0.00353 \\ \hline
\texttt{pctLowEdu} & 0.0900 & 0.0591 \\ \hline
\texttt{pctCollGrad} & 0 & 0.0686 \\ \hline
\texttt{pctEmploy} & 0 & 0.000505 \\ \hline
\texttt{popDensity} & 0.0702 & 0 \\ \hline
\texttt{pctForeignBorn} & 0.0634 & 0.0385 \\ \hline
\end{tabular}
\end{center}

These coefficients are after transformation on both the outcome and several of the explanatory variables which can be seen in the formulae for the models here:

\begin{gather}
\log(nonViolPerPop) = 10.829 - 0.161\mathbbm{1}_{NorthEast} + 0.113\mathbbm{1}_{West} + 0.039\mathbbm{1}_{South} \\ + 0.079\mathbbm{1}_{isUrban>85} - 0.017pctKids2Par + 0.038\log(pctForeignBorn) - 0.003pctWdiv \\ -0.00002e^{\frac{pctHousOccup}{10}} + 0.067\log(pctVacantBoarded+1) + 0.058\log(pctLowEdu) \\ - 0.107\log(rentQrange) - 0.0035pctVacant6up + 0.00051pctEmploy + \\ 0.069\log(pctCollGrad) - 0.065log(ownHousMed) + \epsilon
\end{gather}
\\
\\
\begin{gather}
\log(violentPerPop) = 6.282 - 0.171\mathbbm{1}_{NorthEast} + 0.206\mathbbm{1}_{West} + 0.182\mathbbm{1}_{South} \\ + 0.151\mathbbm{1}_{isUrban>85} - 0.018pctKids2Par + 0.063\log(pctForeignBorn) - 0.011pctWdiv \\ -0.000028e^{\frac{pctHousOccup}{10}} + 0.131\log(pctVacantBoarded+1) + 0.090\log(pctLowEdu) \\ + 0.109\log(rentQrange) - 0.0032pctVacant6up + 0.702pctKidsBornNevrMarr^{0.25} \\ - 0.112\log(medIncome) + 0.069\log(rentMed) + 0.070\log(popDensity) + \epsilon
\end{gather}

From the table we can gather the differences in what affects violent and non-violent crime. `isUrban` has a larger coefficient in the violent crime model than in the non-violent model so we gather that urban areas have higher incidences of both violent and non-violent crime but the effect is much more dramatic for violent crime.
Income appears to be less important in predicting violent crime than non-violent crime since the non-violent model does not include `medIncome` and also has a smaller coefficient than the violent model for `pctWdiv`. However the model for non-violent crime does include `ownHousMed` which is closely related to income. Areas where income is higher or where there are more people receiving dividend or rent income have lower rates of violent crime.
When it comes to housing/rent prices, the median rent price is an important predictor for violent crime - higher rent predicts lower crime rates, while median house prices and rent interquartile range is important for predicting non-violent crime rates. Higher hose prices correspond to lower non-violent crime rates and higher disparity between rent prices --- i.e. more income inequality in an area --- leads to higher rates of non-violent crime.
Both models predict that a higher percentage of children being raised in two-parent homes leads to a lower rate of violent and non-violent crime, but a much larger effect can be seen in the model for violent crime with regards to the percentage of children born to unmarried parents. Having a high coefficient of 0.702, our model predicts that violent crime increases fairly dramatically with a rise in children being born to single parents.
The proportion of housing being occupied has a similarly small effect on crime rates in both models, more housing being left empty leads to a slight increase in both crime rates.
The percentage of vacant and boarded up housing (`pctVacantBoarded`) has a fairly large effect on crime rates --- more so for violent crime --- however the percentage of housing vacant for over 6 months has the opposite (albeit much smaller) effect on crime rates. As such we might expect a county which has a large increase in the percentage of boarded up housing to have an increase in crime rates which would then slowly decrease after about six months. This could, for example, be due to more development in areas where housing has been boarded up however this would be impossible to confirm without looking at other variables which are not included in this data set such as city/county budgets etc.
Low education (defined as people 25 or over with less than 9th grade education) predicts higher rates of both violent and non-violent crime, with a stronger effect being seen for violent crime. On the other hand the percentage of the population who graduated from college predicts higher rates of non-violent crime but doesn't seem to have much effect on rates of violent crime, at least after the proportion of those with low education has been accounted for.
Higher employment rates lead to a fairly small increase in rates of non-violent crime and have not been included in our violent crime model after variable selection - presumably since accounting for income and education already can better explain crime rates than employment can.
A higher population density seems to increase violent crime rates but not non-violent crime, this is consistent with `isUrban` having a larger effect for violent crime than for non-violent crime since we expect urban areas to have more dense populations.
Finally the percentage of population born in a foreign country had an increasing effect on crime rates, more so for violent crime.

So we can see that the factors effecting violent crime are mostly similar. Some variables have different effects as seen by differences in magnitude of coefficients. The two models select different variables in a lot of cases but usually they both select at least one variable to explain a particular factor such as housing/rent prices. The exception here is employment rate, which only seems to affect non-violent crime.

+ Are there areas of the US with unusually low or high crime rates that do not conform to the general pattern?

```{r, echo=FALSE}
# USACrime2$violentError = USACrime2$violentPerPop - predict(violentModelRidge, newx = model.matrix(violentModelAICMin))
# boxplot(USACrime2$violentError ~ USACrime2$State)
# abline(h=0, col = "red")
```
After computing the difference between actual log(violentPerPop) with the predicted log(violentPerPop), we plotted the boxplot of the difference for each state. For most states, the difference is distributed around 0, indicating the model predicts the violent crime rates for those states well. However, state "ND" does not seem to conform with the general pattern of the model, consistently having actual violent crime rates lower than the predicted violent crime rates.

For non violent crime rate on the other hand, difference between actual and predicted values for all states is distributed around 0, so all states conform to the general pattern.

```{r, echo=FALSE}
# USACrime3 = USACrime2[c(-320,-363,-1548),]
# USACrime3$nonViolError = USACrime3$nonViolPerPop - predict(nonViolModelRidge, newx = model.matrix(nonViolModelAICMin))
# boxplot(USACrime3$nonViolError ~ USACrime3$State)
# abline(h=0, col = "red")
```

\newpage

# 2 Statistical Methodology

```{r include=FALSE, message=FALSE}
library(dplyr)
library(e1071)
library(RcmdrMisc)
library(glmnet)
library(olsrr)
library(knitr)
load("~/Documents/University/Year3/ST404/Assignment1/USACrime.Rda")
```

## Cleaning Data

```{r include=FALSE, message=FALSE}
USACrime$ownHousMed[USACrime$ownHousMed==500001] <- NA
USACrime$ownHousQrange[USACrime$ownHousQrange==0] <- NA
USACrime$rentMed[USACrime$rentMed==1001] <- NA
USACrime$rentQrange[USACrime$rentQrange==0] <- NA
USACrime = na.omit(USACrime)
levels(USACrime$region) = c("MidWest", "NorthEast", "West", "South", "West")
USACrime = transform(USACrime, pctUrban = +(pctUrban > 85))
```

After the exploratory data analysis completed assignment 1 we decided to do the following to clean up the data:  

+ Remove the NAs in medIncome and pctEmploy (Figure 1)
+ Remove unexpected values in ownHousMed, ownHousQrange, rentMed and rentQrange (Figure 1)
+ Change the Pacific region to West (Figure 2)
+ Use pctUrban values to create a boolean variable splitting at 85% with 1 bring Urban and 0 being not Urban (Figure 3)

## Transformations

```{r include=FALSE, message=FALSE}
vars<- c(c(4:22))
posVars <- c()
negVars <- c()
for (i in vars) {
  if(skewness(USACrime[,i]) > 0.7){
    posVars <- c(posVars, i)
  }
  if(skewness(USACrime[,i]) < -0.7){
    negVars <- c(negVars, i)
  }
}

USACrime2 = transform(USACrime,
                      medIncome = log(medIncome),
                      pctLowEdu = log(pctLowEdu),
                      pctNotHSgrad = pctNotHSgrad^0.5,
                      pctCollGrad = log(pctCollGrad),
                      pctUnemploy = log(pctUnemploy),
                      pctKidsBornNevrMarr = pctKidsBornNevrMarr^0.25,
                      pctHousOccup = exp(pctHousOccup/10),
                      pctVacantBoarded = log(pctVacantBoarded+1),
                      ownHousMed = log(ownHousMed),
                      ownHousQrange = log(ownHousQrange),
                      rentMed = log(rentMed),
                      rentQrange = log(rentQrange),
                      popDensity = log(popDensity),
                      pctForeignBorn = log(pctForeignBorn),
                      violentPerPop = log(violentPerPop),
                      nonViolPerPop = log(nonViolPerPop))
```

To create a model of this data we must first transform some of the variables that are heavily skewed.  
We decided that a skewness value between -0.7 and 0.7 was acceptable and found the variables that were outside of this range. We will only use this method to transform the explanatory variables and transform the outcome variables to ensure homoscadisity. 

medIncome, pctLowEdu, pctNotHSgrad, pctCollGrad, pctUnemploy, pctKidsBornNevrMarr, pctVacantBoarded, ownHousMed, ownHousQrange, rentQrange, popDensity and pctForeignBorn are all the positively skewd variables and pctHousOccup is the only negatively skewed variable. (Figure 4)

For the positively skewed variables our aim was to get the skewness in the acceptable range so transformed using log and square root and used the least skewed transformation as we look forward to modeling. However variables pctKidsBornNevrMarr and pctVacantBoarded both have 0 vales so cannot use the log transformation so will deal with this separately.  (Figure 5)  

From pctKidsBornNevrMarr, pctVacantBoarded we try square root, 4th root and taking the log(x+1) and from this we see that pctKidsBornNevrMarr should be 4th rooted and pctVacantBoarded should have a log(x+1) transformation.

For the 1 negatively skewed variable, pctHousOccup, taking the exponential of (pctHousOccup/10) completed the transformation to an acceptable level.

The list of transformations for all variables (Figure 6):  

+ medIncome - log 
+ pctLowEdu - log
+ pctNotHSgrad - sqrt
+ pctCollGrad - log
+ pctUnemploy - log
+ ownHousMed - log
+ ownHousQrange - log
+ rentQrange - log
+ popDensity - log
+ pctForeignBorn - log
+ pctKidsBornNevrMarr - 4th root 
+ pctVacantBoarded - log(x + 1) 
+ pctHousOccup - e^(x/10)

## Variables  Selection
During our EDA we gave suggestions of the variables we would recommend for a linear model. We wanted variables that covered the whole data set with high correlation to the outcome variables however low correlation between each other so elected for the following: region, isUrban, pctNotHSgrad, pctWdiv, medIncome, rentQrange, (pctUnemploy or pctEmploy), (pctKids2Par or pctKidsBornNevrMarr), (pctHousOccup or pctHousOwnerOccup), (ownHousMed or rentMed). 

To find the best variables of the ones above we chose to find the combination that minimized the RSS/AIC (as for a fixed number of explanatory variables the result will be the same). The resulting linear models gave an AIC of 3564.779 for violentPerPop and 1777.114 for nonViolPerPop (Figure 7). We will use these models and values as a bench mark for more rigorous model creation.

## Stepwise regression with AIC

```{r include=FALSE}
USACrime2V = USACrime2[,c(-1,-24)]
USACrime2NV = USACrime2[,c(-1,-23)]

violentModelAICMax = stepwise(lm(violentPerPop ~ ., data = USACrime2V), direction = "backward/forward", criterion = "AIC", trace = FALSE)
violentModelAICMin = stepwise(lm(violentPerPop ~ ., data = USACrime2V), direction = "forward/backward", criterion = "AIC", trace = FALSE)

nonViolModelAICMax = stepwise(lm(nonViolPerPop ~ ., data = USACrime2NV), direction = "backward/forward", criterion = "AIC", trace = FALSE)
nonViolModelAICMin = stepwise(lm(nonViolPerPop ~ ., data = USACrime2NV), direction = "forward/backward", criterion = "AIC", trace = FALSE)
```

### Violent Crime Model
We tried applying bidirectional elimination stepwise regression with AIC, one starting with the null model and another starting from the full model. (Figure 8) 

Through this method, we found that both violent crime models have 14 parameters, and only 1 out of the 14 parameters differ (pctHousOwnerOccup in first model, medIncome in second model). Since stepwise regression lead to very similar final models, we can be confident that one of the models is the global optimal model. The coeffients shown below show how similar the models are.

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Variable} & \textbf{AIC backward/forward Model} & \textbf{AIC forward/backward Model} \\ \hline
Intercept & 4.932 & 3.708 \\ \hline
\texttt{region} - North East & -0.203 & -0.205 \\ \hline
\texttt{region} - West & 0.297 & 0.305 \\ \hline
\texttt{region} - South & 0.247 & 0.243 \\ \hline
\texttt{isUrban} & 0.182 & 0.180 \\ \hline
\texttt{pctWdiv} & -0.013 & -0.014  \\ \hline
\texttt{pctLowEdu} & 0.076 & 0.093 \\ \hline
\texttt{pctKids2Par} & -0.033 & -0.035 \\ \hline
\texttt{pctKidsBornNevrMarr} & 0.737 & 0.680 \\ \hline
\texttt{pctHousOccup} & 0.000 & 0.000 \\ \hline
\texttt{pctHousOwnerOccup} & 0.002 & NA \\ \hline
\texttt{pctVacantBoarded} & 0.110 & 0.108 \\ \hline
\texttt{pctVacant6up} & -0.003 & -0.002 \\ \hline
\texttt{medIncome} & N/A & 0.215 \\ \hline
\texttt{rentMed} & 0.289 & 0.186 \\ \hline
\texttt{rentQrange} &  0.123 & 0.114  \\ \hline
\texttt{popDensity} & 0.043 & 0.040 \\ \hline
\texttt{pctForeignBorn} & 0.057 & 0.056 \\ \hline
\end{tabular}
\end{center}

With both models having the same number of parameters, we decided to choose the model with the lower AIC value, which corresponds to the model with the lower mean squared error, violentModelAICMin (AIC value of 3505.804).

### Non Violent Crime Model
Applying the same technique used on violent crime model to non violanet crime model, similars result has been obtained (Figure 8). Both models have 13 of the same explanatory variables and differ only by two variables (first model has pctNotHSgrad and ownHousQrange, while second model has pctCollGrad). Since the two models overlap significantly, we are again confident that the global optimal model is the one with a lower AIC value. The coeffients shown below show how similar the models are.

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Variable} & \textbf{AIC backward/forward Model} & \textbf{AIC forward/backward Model} \\ \hline
Intercept & 12.379 & 11.924 \\ \hline
\texttt{region} - North East & -0.162 & -0.182 \\ \hline
\texttt{region} - West & 0.162 & 0.163 \\ \hline
\texttt{region} - South & 0.015 & 0.006 \\ \hline
\texttt{isUrban} & 0.065 & 0.058 \\ \hline
\texttt{pctWdiv} & 0.005 &  0.005 \\ \hline
\texttt{pctLowEdu} & 0.164 & 0.087 \\ \hline
\texttt{pctNotHSgrad} & -0.084 & N/A \\ \hline
\texttt{pctCollGrad} & N/A & 0.112 \\ \hline
\texttt{pctEmploy} & 0.009 & 0.009 \\ \hline
\texttt{pctKids2Par} & -0.030 & -0.029 \\ \hline
\texttt{pctHousOccup} & 0.000 & 0.000 \\ \hline
\texttt{pctVacantBoarded} & 0.045 & 0.041  \\ \hline
\texttt{pctVacant6up} & -0.003 & -0.003 \\ \hline
\texttt{ownHousMed} & -0.258 & -0.172 \\ \hline
\texttt{ownHousQrange} & 0.085 & N/A \\ \hline
\texttt{rentQrange} & -0.092  & -0.119  \\ \hline
\texttt{pctForeignBorn} & 0.081 & 0.076 \\ \hline
\end{tabular}
\end{center}

With nonViolModelAICMin having a lower AIC value 1523.04 and lower number of parameters, it is our chosen model.

Both of these produced better AIC values than our EDA produced benchmark.

## LASSO regression

We also wanted to consider penalised regression methods for finding an optimal linear model. Here, we use LASSO regression which will perform both variable selection and coefficient penalisation. We started with all of the possible explanatory variables (excluding `State`) and ran a LASSO regression algorithm which gave us the following plots:

```{r echo = FALSE, fig.height=3.5}
set.seed(1234)
X1 <- model.matrix(lm(violentPerPop ~ 1 + ., data = USACrime2[-c(1,24)]))
X2 <- model.matrix(lm(nonViolPerPop ~ 1 + ., data = USACrime2[-c(1,23)]))
y1 <- log(USACrime$violentPerPop)
y2 <- log(USACrime$nonViolPerPop)
fitA <- glmnet(X1, y1, alpha = 1)
fitB <- glmnet(X2, y2, alpha = 1)
{plot(fitA, xvar = "lambda", label = TRUE, main = "LASSO Regression on Violent Crime", cex.main = .7)
plot(fitB, xvar = "lambda", label = TRUE, main = "LASSO Regression on Non-Violent Crime", cex.main = .7)}
```

Note that the variables `region`, `isUrban`, `pctHousOccup` and `pctHousOwnerOccup` still have non-zero coefficients for higher values of lambda (our penalty factor) in the case of violent crime, and `region`, `isUrban`, `pctHousOccup` and `pctWdiv` have non-zero coefficients for higher values of lambda. This is fairly consistent with what we found when using stepwise regression for variable selection: `region` and `isUrban` are identified as important by both stepwise and LASSO regression for both types of crime. We also see that `pctHousOccup` and `pctWdiv` are important explanatory variables for non-violent crime according to both stepwise and LASSO regression. Additionally `pctHousOccup` is chosen by stepwise regression for violent crime and is kept for most values of lambda in lasso regression. The only difference we see is that `pctHousOwnerOccup` is not chosen by stepwise regression when modelling violent crime rates but it is kept for most values of lambda by LASSO, although with a very small coefficient.

Here we find optimal values of lambda to minimise error in the model:

```{r echo = FALSE, fig.height=4}
set.seed(1234)
model5A <- cv.glmnet(X1, y1, alpha = 1)
model5B <- cv.glmnet(X2, y2, alpha = 1)
{par(mfrow = c(1, 2))
plot(model5A, sub = "Violent Crime")
plot(model5B, sub = "Non-Violent Crime")}
```

We take the value of lambda as the maximum which is one standard error away from the value of lambda which minimises mean square error, which for violent crime is $\lambda = 0.05445$ and for non-violent crime is
$\lambda = 0.03881$. We then get the following model coefficients (rounded to 3 significant figures):

\begin{center}
\begin{tabular}{|c|c|c|}
\hline
\textbf{Variable} & \textbf{Violent} & \textbf{Non-Violent} \\ \hline
Intercept & 7.49 & 10.6 \\ \hline
\texttt{region} - North East & -0.132 & -0.237 \\ \hline
\texttt{region} - West & 0.209 & 0.0273 \\ \hline
\texttt{region} - South & 0.136 & 0 \\ \hline
\texttt{isUrban} & 0.157 & 0.0292 \\ \hline
\texttt{pctWdiv} & -0.0116 & 0 \\ \hline
\texttt{pctKids2Par} & -0.0338 & -0.0250 \\ \hline
\texttt{pctKidsBornNevrMarr} & 0.774 & 0 \\ \hline
\texttt{pctHousOccup} & -0.0000165 & -0.0000114 \\ \hline
\texttt{pctHousOwnerOccup} & 0 & -0.00258 \\ \hline
\texttt{pctVacantBoarded} & 0.0279 & 0.00579 \\ \hline
\texttt{pctVacant6up} & 0 & -0.000767 \\ \hline
\texttt{ownHousQrange} & 0.0142 & 0 \\ \hline
\texttt{pctForeignBorn} & 0.107 & 0.0188 \\ \hline
\texttt{rentQrange} & 0 & -0.0265 \\ \hline
\end{tabular}
\end{center}

A problem with these models is that they both select pairs of variables which have very high correlation. For example the model for violent crime picks both `pctKids2Par` and `pctKidsBornNevrMarr` and the non-violent model picks both `pctVacantBoarded` and `pctVacant6up` and as such these models are likely to have problems regarding multicollinearity. Additionally we see that not all levels of the categorical variable `region` have been given coefficients in the model for non-violent crime which is problematic since we know there are differences in crime rates across regions.
To address this, we try taking the the variables picked by the LASSO regression and fit a normal least squares regression on those variables (Figure 10):  
The violent crime linear model with LASSO chosen variables has a AIC of 3520.328  
The violent crime linear model with LASSO chosen variables has a AIC of 1731.793  

We find that these models are not an improvement on our previous models which used stepwise regression to select variables and then ridge regression to apply a penalty to the coefficients. These models which use the variables selected by LASSO without penalty have a higher AIC and as such we abandon these models.

## Compareing the 2 models
After completing the two model creation methods we now have to decide which models are better for each of the outcome variables. To do this we calculated the Mean Square Error for each of the models (Figure 11).  
Getting the following results:

+ violentModelAIC MSE = 0.398177113804347
+ nonViolModelAIC MSE = 0.145304970809664
+ violentModelLASSO MSE = 0.42072263243735
+ nonViolModelLASSO MSE = 0.157273523662924

From this we see that the AIC models give the lowest MSE.

## Outliers and Multicollinearity
After finalising the model parameters, there may be outliers or multicollinearity affecting the parameter coefficients of our model, thus we need to investigate further into the variables.

### Volient Crime Model
```{r echo = FALSE, fig.height=3.5}
plot(violentModelAICMin, which = 3)
```
Through the standarised residuals plot, we conclude that there are no outliers. However, before finalising the parameter coefficients, we noticed that the model fitted certain variables which had some correlation with each other, such as rentMed with medIncome. 

Including variables which are highly correlated with each other in the linear model may lead to unreliable parameter coefficients. Therefore, we compute the variance inflation factors to check for multicollinearity in our model.

With pctKids2Par, pctKidsBornNevrMarr, medIncome and rentMed having variance inflation factor >5, it is evidence of multicollinearity being present in our model. To mitigate this, we decided to set our parameter coefficients using cross validation ridge regression. (Figure 12)

### Non Violent Crime Model
```{r echo = FALSE, fig.height=4}
plot(nonViolModelAICMin, which = 3)
```
The standardized residuals plot above shows that there are 3 outliers. Although further investigation suggests that the 3 observations are valid, we would still remove them from the dataset before fitting a linear model to prevent the 3 outliers from affecting the model.

```{r echo = FALSE, fig.height=4}
USACrime2NV = USACrime2NV[c(-320,-363,-1548),]

nonViolModelAICMin = lm(nonViolPerPop ~ region
                        + pctKids2Par
                        + pctHousOccup
                        + pctForeignBorn
                        + rentQrange
                        + pctEmploy
                        + pctCollGrad
                        + ownHousMed
                        + pctVacant6up
                        + pctLowEdu
                        + pctUrban
                        + pctWdiv
                        + pctVacantBoarded
                        , data = USACrime2NV)

plot(nonViolModelAICMin, which = 3)
```
From the new standardised residual plot we conclude there are no more outliers, and proceed to the next stage of our model investigation, multicollinearity.

The VIF value provides some evidence of multicollinearity as ownHousMed and pctWdiv has a variance inflation factor >5. Thus, similar to the violent crime model, we mitigate this by applying cross validation ridge regression to find the appropriate coefficients for our non violent crime model. (Figure 13)

## Final Model
Using 2 stepwise regression to finalise the model parameters, together with cross validation ridge regression to manage multicollinearity in our model parameters and maximise the predictive power of our model concurrently, we have found our final model parameters for both volient and non violent crime.

\newpage
# 3 Appendix  

Packages
```{r eval = FALSE, message=FALSE}
library(dplyr)
library(e1071)
library(RcmdrMisc)
library(glmnet)
load("~/Documents/University/Year3/ST404/Assignment1/USACrime.Rda")
```

Figure 1 - Removing unexpected values and NA values
```{r eval = FALSE}
USACrime$ownHousMed[USACrime$ownHousMed==500001] <- NA
USACrime$ownHousQrange[USACrime$ownHousQrange==0] <- NA
USACrime$rentMed[USACrime$rentMed==1001] <- NA
USACrime$rentQrange[USACrime$rentQrange==0] <- NA
USACrime = na.omit(USACrime)
```

Figure 2 - Changing Pacific region to West
```{r eval = FALSE}
levels(USACrime$region) = c("MidWest", "NorthEast", "West", "South", "West")
```

Figure 3 - Changing the pctUrban variables to factor
```{r eval = FALSE}
USACrime = transform(USACrime, pctUrban = +(pctUrban > 85))
```

Figure 4 - Finding variables that need to be transformed
```{r eval = FALSE}
vars<- c(c(4:22))
posVars <- c()
negVars <- c()
for (i in vars) {
  if(skewness(USACrime[,i]) > 0.7){
    posVars <- c(posVars, i)
  }
  if(skewness(USACrime[,i]) < -0.7){
    negVars <- c(negVars, i)
  }
}
```

Figure 5 - Finding best transformations for positively skewed variables
```{r eval = FALSE}
posVars2 <- posVars[posVars != 12]
posVars2 <- posVars2[posVars2 != 15]
for (i in posVars2){
  a <- abs(skewness(USACrime[,i]))
  b <- abs(skewness(log(USACrime[,i])))
  c <- abs(skewness(sqrt(USACrime[,i])))
  z <- NA
  y <- min(a,b,c)
  if (y == a){
    z <- "normal"
  }
  else if(y == b){
    z <- "log"
  }
  else{
    z <- "sqrt"
  }
  print(paste(colnames(USACrime[i]),z,min(a,b,c)))
}
```

Figure 6 - Transformations
```{r eval = FALSE}
USACrime2 = transform(USACrime,
                      medIncome = log(medIncome),
                      pctLowEdu = log(pctLowEdu),
                      pctNotHSgrad = pctNotHSgrad^0.5,
                      pctCollGrad = log(pctCollGrad),
                      pctUnemploy = log(pctUnemploy),
                      pctKidsBornNevrMarr = pctKidsBornNevrMarr^0.25,
                      pctHousOccup = exp(pctHousOccup/10),
                      pctVacantBoarded = log(pctVacantBoarded+1),
                      ownHousMed = log(ownHousMed),
                      ownHousQrange = log(ownHousQrange),
                      rentMed = log(rentMed),
                      rentQrange = log(rentQrange),
                      popDensity = log(popDensity),
                      pctForeignBorn = log(pctForeignBorn),
                      violentPerPop = log(violentPerPop),
                      nonViolPerPop = log(nonViolPerPop))
```

Figure 7 - RSS minimization for EDA Variables
```{r eval = FALSE}
RSSVMin <- Inf
modelDataVMinRSS <- NULL
for (i in 1:2) {
  for(j in 1:2){
    for (k in 1:2) {
      for (l in 1:2) {
        modelData <- subset(USACrime2, select =
                    c(region,pctUrban,pctNotHSgrad,pctWdiv,medIncome,rentQrange,
                    c(pctUnemploy, pctEmploy)[i],
                    c(pctKids2Par,pctKidsBornNevrMarr)[j],
                    c(pctHousOccup, pctHousOwnerOccup)[k], 
                    c(ownHousMed, rentMed)[l]))
        lmA <- lm(USACrime2$violentPerPop ~ ., modelData)
        if (sum(residuals(lmA)^2) < RSSVMin) {
          RSSVMin <- sum(residuals(lmA)^2)
          modelDataVMinRSS <- modelData
        }
      }
    }
  }
}
lmVMinRSS <- lm(USACrime2$violentPerPop ~ ., modelDataVMinRSS)

RSSNVMin <- Inf
modelDataNVMinRSS <- NULL
for (i in 1:2) {
  for(j in 1:2){
    for (k in 1:2) {
      for (l in 1:2) {
        modelData <- subset(USACrime2, select =
                    c(region,pctUrban,pctNotHSgrad,pctWdiv,medIncome,rentQrange,
                    c(pctUnemploy, pctEmploy)[i],
                    c(pctKids2Par,pctKidsBornNevrMarr)[j],
                    c(pctHousOccup, pctHousOwnerOccup)[k], 
                    c(ownHousMed, rentMed)[l]))
        lmA <- lm(USACrime2$nonViolPerPop ~ ., modelData)
        if (sum(residuals(lmA)^2) < RSSNVMin) {
          RSSNVMin <- sum(residuals(lmA)^2)
          modelDataNVMinRSS <- modelData
        }
      }
    }
  }
}
lmNVMinRSS <- lm(USACrime2$nonViolPerPop ~ ., modelDataVMinRSS)
```

Figure 8 - Stepwise regression with AIC
```{r eval = FALSE}
#REMOVING STATES AND VIOL/NONVIOL
USACrime2V = USACrime2[,c(-1,-24)]
USACrime2NV = USACrime2[,c(-1,-23)]

#VIOL AIC
violentModelAICMax = stepwise(lm(violentPerPop ~ ., data = USACrime2V), direction = "backward/forward", criterion = "AIC", trace = FALSE)
violentModelAICMin = stepwise(lm(violentPerPop ~ ., data = USACrime2V), direction = "forward/backward", criterion = "AIC", trace = FALSE)

#NONVIOL AIC
nonViolModelAICMax = stepwise(lm(nonViolPerPop ~ ., data = USACrime2NV), direction = "backward/forward", criterion = "AIC", trace = FALSE)
nonViolModelAICMin = stepwise(lm(nonViolPerPop ~ ., data = USACrime2NV), direction = "forward/backward", criterion = "AIC", trace = FALSE)
```

Figure 9 - LASSO Regression
```{r eval = FALSE}
set.seed(1234)
modelLassoA <- lm(violentPerPop ~ 1 + ., data = USACrime2[-c(1,24)])
modelLassoB <- lm(nonViolPerPop ~ 1 + ., data = USACrime2[-c(1,23)])
X1 <- model.matrix(modelLassoA)
X2 <- model.matrix(modelLassoB)
y1 <- log(USACrime$violentPerPop)
y2 <- log(USACrime$nonViolPerPop)
fitA <- glmnet(X1, y1)
fitB <- glmnet(X2, y2)
plot(fitA, xvar = "lambda")
plot(fitB, xvar = "lambda")
model5A <- cv.glmnet(X1, y1)
model5B <- cv.glmnet(X2, y2)
model5A
model5B
```


Figure 10 - Linear models AIC using LASSO regression variables
```{r eval = FALSE}
model6A <- lm(violentPerPop ~ region + pctUrban + pctWdiv + pctKids2Par + pctKidsBornNevrMarr + pctHousOccup + pctVacantBoarded + pctForeignBorn + ownHousQrange, data = USACrime2)
model6B <- lm(nonViolPerPop ~ region + pctUrban + pctKids2Par + pctKidsBornNevrMarr + pctHousOccup + pctHousOwnerOccup + pctVacantBoarded + pctVacant6up + pctForeignBorn + rentQrange, data = USACrime2)
AIC(model6A)
AIC(model6B)
```

Figure 11 - MSE of the models from stepwise regression with AIC and LASSO
```{r eval = FALSE}
paste("violentModelAIC MSE =",mean(violentModelAICMin$residuals^2))
paste("nonViolModelAIC MSE =",mean(nonViolModelAICMin$residuals^2))
paste("violentModelLASSO MSE =",model5A$cvm[model5A$lambda == model5A$lambda.1se])
paste("nonViolModelLASSO MSE =",model5B$cvm[model5B$lambda == model5B$lambda.1se])
```

Figure 12 - Outliers, Multicollinearity and Ridge Regression for violent crime model
```{r eval = FALSE}
plot(violentModelAICMin, which = 3)
ols_vif_tol(violentModelAICMin)
violentModelRidge = cv.glmnet(model.matrix(violentModelAICMin), USACrime2V$violentPerPop, alpha = 0)
coef(violentModelRidge)
```

Figure 13 - Outliers, Multicollinearity and Ridge Regression for non violent crime model
```{r eval = FALSE}
plot(nonViolModelAICMin, which = 3)
USACrime2NV = USACrime2NV[c(-320,-363,-1548),]
nonViolModelAICMin = lm(nonViolPerPop ~ region
                        + pctKids2Par
                        + pctHousOccup
                        + pctForeignBorn
                        + rentQrange
                        + pctEmploy
                        + pctCollGrad
                        + ownHousMed
                        + pctVacant6up
                        + pctLowEdu
                        + pctUrban
                        + pctWdiv
                        + pctVacantBoarded
                        , data = USACrime2NV)

plot(nonViolModelAICMin, which = 3)
ols_vif_tol(nonViolModelAICMin)
nonViolModelRidge = cv.glmnet(model.matrix(nonViolModelAICMin), USACrime2NV$nonViolPerPop, alpha = 0)
coef(violentModelRidge)
```
